{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "discrete-league",
   "metadata": {},
   "source": [
    "# Alpha Separation\n",
    "We have a picture of a piece of metal. In the image are two types of alpha crystal - Primary alpha are round large blobs and secondary alpha is the smaller needle like crystals. The objective is to create an image mask to separate the two types of crystal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color, measure, morphology\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-administrator",
   "metadata": {},
   "source": [
    "## Import image\n",
    "It's stored as RGBA so convert to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gray(image: np.ndarray):\n",
    "    \"\"\"Plot the supplied array as an image in greyscale.\"\"\"\n",
    "    io.imshow(image, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_color(image: np.ndarray):\n",
    "    \"\"\"Plot the supplied array as an image using the standard colormap.\"\"\"\n",
    "    io.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread(\"BSE 200um FW.png\")\n",
    "gray_image = color.rgb2gray(color.rgba2rgb(image))\n",
    "plot_gray(gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-judges",
   "metadata": {},
   "source": [
    "## Crop image\n",
    "Remove white borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = 0\n",
    "x_max = 1093\n",
    "y_min = 21\n",
    "y_max = 843\n",
    "gray_image = gray_image[y_min:y_max, x_min:x_max]\n",
    "plot_gray(gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-crossing",
   "metadata": {},
   "source": [
    "## What is interesting to the human eye about this image?\n",
    "This will inform our approach for the analysis.\n",
    "\n",
    "One notable aspect is that the primary alpha tends to be more oval while the rods have a much higher aspect ratio. There are some high aspect ratio primary alpha sections, but these are on a much larger scale. On average the primary alpha regions are bigger than the secondary alpha.\n",
    "\n",
    "There is some white background that is neither primary nor secondary. All secondary is close to some white background, but the center of the alpha is not close to any white."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-hammer",
   "metadata": {},
   "source": [
    "## Attempt 1: Characterise distance of pixels from white background\n",
    "- First threshold the image to get the white particles and non-white particles\n",
    "- Then for all non-white pixels, measure the average distance to the nearest half dozen white pixels\n",
    "\n",
    "### Filter image\n",
    "Setting the threshold slightly on the low side is good here. Some noise in the primary alpha is probably better than losing definition from the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_image_display(image: np.ndarray, threshold: int):\n",
    "    print(image.shape)\n",
    "    mask = (image > threshold).astype(int)\n",
    "    plot_gray(mask)\n",
    "    print(f\"{image.size} total pixels\")\n",
    "    print(f\"{np.sum(mask)} background pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(threshold_image_display, image=fixed(gray_image), threshold=widgets.FloatSlider(min=0, max=1, step=1/256, value=0.45, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-blackberry",
   "metadata": {},
   "source": [
    "A threshold of 0.45 pretty much separates the alpha and the background.\n",
    "\n",
    "### Measure distance from each pixel to the background \n",
    "Select the background pixels using the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to re-stack the indices here as np.where returns the columns and rows separately.\n",
    "background_pixel_locations = np.column_stack(np.where(gray_image > 0.45))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-antenna",
   "metadata": {},
   "source": [
    "Now measure the distance between each particle in the image and its N nearest background particles (background has value of 1)\n",
    "\n",
    "For testing purposes it is best to set the x_lim and y_lim to do a small subregion. A 200x200 section takes on the order of 1 minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = 10\n",
    "\n",
    "x_lim = 200\n",
    "y_lim = 200\n",
    "new_image = []\n",
    "indices = np.indices((1, y_lim)).reshape(2, y_lim).T\n",
    "for x in tqdm(range(x_lim)):\n",
    "    # Do cdist in sqeuclidean and sqrt the end result to save time.\n",
    "    distances = scipy.spatial.distance.cdist(indices, background_pixel_locations, 'sqeuclidean')\n",
    "    # Get the indices of the N closest background pixels\n",
    "    shortest_indices = np.argpartition(distances, num_pixels, axis=1)[:, :num_pixels]\n",
    "    # Get the distances of the N closest background pixels using the indices.\n",
    "    # Indexing a 2D array with a 2D array is weird... no idea why it is this hard.\n",
    "    distance_to_background = np.mean(distances[np.arange(distances.shape[0])[:, None], shortest_indices], axis=1)\n",
    "    new_image.append(distance_to_background)\n",
    "    indices[:, 0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.sqrt(np.array(new_image).reshape(x_lim, y_lim))\n",
    "plot_color(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-distinction",
   "metadata": {},
   "source": [
    "Now threshold again - primary alpha is the higher values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 8\n",
    "\n",
    "primary_alpha = distance.copy()\n",
    "primary_alpha_indices = np.column_stack(np.where(primary_alpha > threshold))\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.scatter(primary_alpha_indices[:, 1], primary_alpha_indices[:, 0], s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-hawaii",
   "metadata": {},
   "source": [
    "This has worked pretty well. It is picking up just a touch of secondary alpha at (80,180) but this could be removed by labelling image regions and filtering on size. \n",
    "\n",
    "The marked region needs to be expanded a little to capture the full alpha region. This can be done by applying a circle brush to each identified point. This can be easily simulated by changing the scatter plot points to be bigger - a brush of about 30px is about right.\n",
    "\n",
    "This algorithm is also pretty slow - about 20 minutes for this sample image. 30% of this is due to argparse but this is needed to prevent noise disrupting the signal (perhaps some filtering would preclude this). The rest of the time is in cdist, and I don't think there is any way to game this. My basic implementation of a cell list turns out slower because it isn't vectorised. It would be lighting fast compiled as C with a cell list but meh... too much effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-celebration",
   "metadata": {},
   "source": [
    "# Attempt 2 - A simpler filter\n",
    "What about just trying to threshold and then dilate?\n",
    "\n",
    "First we must do some denoising of the thresholded image. A basic gaussian blur strong enough to bring salt and pepper noise below the threshold would greatly reduce the crispness of the background - it is too blunt an instrument. Mostly we want to just get the single white pixels in the black regions as these will cause problems with the dilation. We can do this by considering the neighbourhood of the noise particles. Any white pixels mostly surrounded by black pixels are considered noise. Even with this method, the thresholds cannot be set too agressively as this blurs the edges between the alpha and the background.\n",
    "\n",
    "The result shouldn't look much different - it should just be the odd speckle from the big primary alpha sections that is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = (gray_image > 0.48).astype(int)\n",
    "plot_gray(binary)\n",
    "\n",
    "mask_size = 4\n",
    "threshold_pixels = 5\n",
    "\n",
    "for x in range(mask_size, binary.shape[0] - mask_size):\n",
    "    for y in range(mask_size, binary.shape[1] - mask_size):\n",
    "        if binary[x, y] == 1:\n",
    "            if np.sum(binary[x - mask_size:x + mask_size, y - mask_size:y + mask_size]) < threshold_pixels:\n",
    "                binary[x, y] = 0\n",
    "\n",
    "plot_gray(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-windows",
   "metadata": {},
   "source": [
    "Now try a dilation x times. Too much dilation is bad as it will dilate the structures we want to keep. Too little dilation and the primary and secondary regions will still be contiguous. About 6 or 7 seems good for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated_binary = binary.copy()\n",
    "\n",
    "for x in range(7):\n",
    "    dilated_binary = morphology.dilation(dilated_binary)\n",
    "plot_gray(dilated_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-savings",
   "metadata": {},
   "source": [
    "Now the regions are seperate, label contiguous regions. Labelling will label white regions, so the image must be inverted using a logical not. This puts the background as label zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled = morphology.label(np.logical_not(dilated_binary))\n",
    "plot_color(labelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now iterate through the labels, removing small ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 80\n",
    "\n",
    "label_props = measure.regionprops(labelled)\n",
    "for index, label in enumerate(label_props):\n",
    "    if label[\"area\"] < threshold:\n",
    "        # Regionprops starts at label 1 so must increment index by 1\n",
    "        labelled[labelled == index + 1] = 0\n",
    "plot_color(labelled)\n",
    "\n",
    "mask = np.column_stack(np.where(labelled != 0))\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.scatter(mask[:, 1], mask[:, 0], s=3, alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-maker",
   "metadata": {},
   "source": [
    "Pretty good! The repeated dilations have removed some smaller primary alpha particles. It might be better to do fewer dilations and a smarter filtering of the labels - perhaps using the eccentricity or one of the other label properties.\n",
    "\n",
    "This could be done by manually identifying labels that are desired, and those that are not and clustering their properties - perhaps an opportunity for *sklearn.cluster*. I initially thought it would be too hard to get the secondary and the primary non-contiguous without wiping out all the detail which is why I tried the complicated method first. This one looks similarly robust and runs in seconds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}